{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b977d89"
      },
      "source": [
        "## Install Dependencies\n",
        "\n",
        "First of all you have to install the necessary libraries for YOLOv8 (ultralytics), DeepSORT, and other utilities like OpenCV.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vSyLI0zr2Ukk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4af3ae7"
      },
      "source": [
        "\n",
        "To install the required libraries, I will use pip install commands in a code block.\n",
        "\n",
        "-Ultralytics is being used since its the repository for the YOLO model we will be using.\n",
        "\n",
        "-OpenCV is a crucial library since it deals with video and image processing (in charge of our boundning boxes and output video)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f0f27d3",
        "outputId": "6f89e0b0-f6c0-48a7-c509-eee1d93b0818"
      },
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install ultralytics\n",
        "!{sys.executable} -m pip install opencv-python\n",
        "!{sys.executable} -m pip install ipython"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.3.236)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.18 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.18)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.12/dist-packages (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from ipython) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython) (0.2.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython) (0.2.14)\n",
            "Core libraries re-installed successfully. DeepSORT installation will be addressed if needed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Its a hassle to install deepsort without having the core AKA pytorch so this is the installation before we install deepsort. Here we are verifying that pytorch is installed and is correctly configured to use your system's GPU."
      ],
      "metadata": {
        "id": "97y7dpdRodWV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e477f24b",
        "outputId": "fba8dc73-69ca-46cb-ce23-8067692465d5"
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available! Installing PyTorch with CUDA support.\")\n",
        "    cuda_version = torch.version.cuda\n",
        "    print(f\"Detected CUDA version: {cuda_version}\")\n",
        "    # The exact command depends on the PyTorch version and CUDA version.\n",
        "    # For Colab, a common command for the latest stable version would be:\n",
        "    # !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "    # (replace cu121 with your detected CUDA version if different)\n",
        "    print(\"You may need to run a specific command based on your exact CUDA version.\")\n",
        "    print(\"Refer to the official PyTorch installation guide for the precise command:\")\n",
        "    print(\"https://pytorch.org/get-started/locally/\")\n",
        "else:\n",
        "    print(\"CUDA is not available. Installing PyTorch CPU version.\")\n",
        "    # Command for CPU-only version\n",
        "    !pip install torch torchvision torchaudio\n",
        "\n",
        "print(\"PyTorch installation process initiated. Please follow any further instructions from the PyTorch website for specific CUDA versions if needed.\")\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available! Installing PyTorch with CUDA support.\n",
            "Detected CUDA version: 12.6\n",
            "You may need to run a specific command based on your exact CUDA version.\n",
            "Refer to the official PyTorch installation guide for the precise command:\n",
            "https://pytorch.org/get-started/locally/\n",
            "PyTorch installation process initiated. Please follow any further instructions from the PyTorch website for specific CUDA versions if needed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c3ac66b",
        "outputId": "941af224-bc36-4929-dc96-baba4ef7b51a"
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"PyTorch is successfully installed with CUDA support!\")\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
        "    print(f\"Current GPU device name: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "    # Test a simple operation on the GPU\n",
        "    a = torch.tensor([1.0, 2.0, 3.0]).cuda()\n",
        "    b = torch.tensor([4.0, 5.0, 6.0]).cuda()\n",
        "    c = a + b\n",
        "    print(f\"Sample tensor operation on GPU: {c}\")\n",
        "else:\n",
        "    print(\"PyTorch CUDA is NOT available or not correctly installed.\")\n",
        "    print(\"Please ensure you have a CUDA-enabled GPU and that PyTorch was installed with CUDA support.\")\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch is successfully installed with CUDA support!\n",
            "CUDA version: 12.6\n",
            "Number of GPUs available: 1\n",
            "Current GPU device name: Tesla T4\n",
            "Sample tensor operation on GPU: tensor([5., 7., 9.], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This part is just a regular pytorvch installation"
      ],
      "metadata": {
        "id": "1ZdwHiqvqDaQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdee0aab",
        "outputId": "4dd0bd0c-a662-40df-b225-d30e4715ec69"
      },
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we since we installed pytorch we can install deepsort to use with our model. If you dont install pytorch first it will have incompatability errors."
      ],
      "metadata": {
        "id": "eNYMNSe5qSI1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5f8c713",
        "outputId": "ceb07566-ac01-4ec6-e043-5bdbc0bde71f"
      },
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install deep-sort-realtime\n",
        "\n",
        "print(\"DeepSORT library (deep-sort-realtime) installed successfully.\")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deep-sort-realtime in /usr/local/lib/python3.12/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from deep-sort-realtime) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from deep-sort-realtime) (1.16.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from deep-sort-realtime) (4.12.0.88)\n",
            "DeepSORT library (deep-sort-realtime) installed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code block is initializing the DeepSORT tracker that we will be using for our human tracking model.\n",
        "\n",
        "\n",
        "1.   max-iou-distance = helps maintain track identity even if detections are slightly noisy.\n",
        "2.   max-age = this parameter determines how many consecutive frames a track can go without being associated with a new detection before it's deleted.\n",
        "3.   n_inint = This parameter specifies the number of consecutive detections required to establish a new confirmed track.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_xptGIjxqvfy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2d788ce",
        "outputId": "d2f12f47-9270-4aea-9009-0939977e5e05"
      },
      "source": [
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "\n",
        "# Initialize DeepSORT tracker with custom parameters\n",
        "tracker = DeepSort(max_iou_distance=0.8, max_age=10, n_init=3) # Adjusted parameters\n",
        "\n",
        "print(\"DeepSORT tracker initialized successfully with adjusted parameters.\")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DeepSORT tracker initialized successfully with adjusted parameters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b99ec19c"
      },
      "source": [
        "## Loading the models and initializing the tracker\n",
        "\n",
        "Load the pre-trained YOLOv8 model for object detection and prepare for tracking.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dc92e31"
      },
      "source": [
        "**Reasoning**:\n",
        "We load ultralytics once again for safety and security even though its installed in the first code block.We the instantiate it with the desired model weights, which will be 'yolov8n.pt'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae180f9b",
        "outputId": "db08741f-b164-4c7f-d2f6-957393f995b0"
      },
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a pre-trained YOLOv8 model\n",
        "model = YOLO('yolov8n.pt')  # Using 'yolov8n.pt' for its balance of speed and accuracy\n",
        "\n",
        "print(\"YOLOv8 model loaded successfully.\")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv8 model loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfdea4d2"
      },
      "source": [
        "## Process Video for Tracking\n",
        "\n",
        "Next we will make sure our model reads the uploaded video file, frame by frame. For each frame, it will perform object detection using YOLOv8 and then apply tracking to the detected humans. Draw bounding boxes and unique IDs on the tracked objects.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf466bfe"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to define the input and output video paths, import `cv2`, open the input video, set up the `VideoWriter`, and then iterate through each frame to perform object detection and tracking using the pre-trained YOLOv8 model. The `model.track` method will be used for tracking, focusing on the 'person' class, and annotations will be drawn on the frames before saving to an output video.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **##IMPORTANT MAKE SURE TO NAME YOUR VIDEO input_video and that its also a mp4 format!**"
      ],
      "metadata": {
        "id": "DAdgL-iNshiA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3731038b",
        "outputId": "073e8b1f-8988-4818-cef5-040a81627fef"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Ensure the DeepSort tracker and YOLOv8 model are already loaded/initialized from previous steps\n",
        "\n",
        "# Load a pre-trained YOLOv8 model (re-added for robustness)\n",
        "model = YOLO('yolov8n.pt')  # Using 'yolov8n.pt' for its balance of speed and accuracy\n",
        "\n",
        "# Define input and output video paths\n",
        "input_video_path = 'input_video.mp4' # This should be the path to your uploaded video\n",
        "output_video_path = 'output_video_deepsort.mp4'\n",
        "\n",
        "# Ensure the input video exists or prompt user to upload\n",
        "# This logic was already handled in a previous cell, but re-including for completeness\n",
        "# if not os.path.exists(input_video_path):\n",
        "#     print(f\"'{input_video_path}' not found. Please upload the video file.\")\n",
        "#     uploaded = files.upload()\n",
        "#     if not uploaded:\n",
        "#         raise FileNotFoundError(\"No file was uploaded. Please upload a video file.\")\n",
        "#     input_video_path = list(uploaded.keys())[0]\n",
        "#     print(f\"Using uploaded file: '{input_video_path}'\")\n",
        "# else:\n",
        "#     print(f\"Using existing file: '{input_video_path}'\")\n",
        "\n",
        "# Open the video file\n",
        "video_cap = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "# Get video properties\n",
        "frame_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Codec for .mp4\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "print(f\"Processing video: {input_video_path} with DeepSORT\")\n",
        "print(f\"Output video will be saved to: {output_video_path}\")\n",
        "\n",
        "frame_count = 0\n",
        "while video_cap.isOpened():\n",
        "    ret, frame = video_cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 7a. Perform object detection using the pre-loaded YOLOv8 model\n",
        "    # Only detect 'person' class (class ID 0 in COCO dataset)\n",
        "    results = model.predict(frame, classes=[0], conf=0.5, iou=0.5)\n",
        "\n",
        "    detections = []\n",
        "    if results[0].boxes is not None:\n",
        "        # 7b. Filter detections to only include 'person' class\n",
        "        # 7c. Extract bounding boxes (xmin, ymin, xmax, ymax) and confidence scores\n",
        "        # Convert bounding box coordinates to the format expected by DeepSORT (top-left x, top-left y, width, height)\n",
        "        for box in results[0].boxes.data:\n",
        "            xmin, ymin, xmax, ymax, conf, class_id = box.tolist()\n",
        "            # DeepSORT expects (x, y, w, h)\n",
        "            w = xmax - xmin\n",
        "            h = ymax - ymin\n",
        "            detections.append(([xmin, ymin, w, h], conf, class_id))\n",
        "\n",
        "    # 7d. Update the DeepSORT tracker\n",
        "    tracks = tracker.update_tracks(detections, frame=frame)\n",
        "\n",
        "    # Create a copy of the frame for drawing annotations\n",
        "    annotated_frame = frame.copy()\n",
        "\n",
        "    # 7e. Iterate through the updated tracks from DeepSORT and draw annotations\n",
        "    for track in tracks:\n",
        "        if not track.is_confirmed():\n",
        "            continue\n",
        "\n",
        "        track_id = track.track_id\n",
        "        ltrb = track.to_ltrb()\n",
        "\n",
        "        # Generate a unique color for each track ID\n",
        "        # Using a simple hash based on track_id for color generation\n",
        "        color_seed = int(str(hash(track_id))[-3:]) # Use last 3 digits of hash for color variation\n",
        "        b = (color_seed * 17) % 255\n",
        "        g = (color_seed * 37) % 255\n",
        "        r = (color_seed * 53) % 255\n",
        "        track_color = (b, g, r)\n",
        "\n",
        "        # Bounding box coordinates\n",
        "        bbox_xmin, bbox_ymin, bbox_xmax, bbox_ymax = int(ltrb[0]), int(ltrb[1]), int(ltrb[2]), int(ltrb[3])\n",
        "\n",
        "        # Draw bounding box\n",
        "        cv2.rectangle(annotated_frame, (bbox_xmin, bbox_ymin), (bbox_xmax, bbox_ymax), track_color, 2)\n",
        "\n",
        "        # Put track ID text\n",
        "        cv2.putText(annotated_frame, f\"ID: {track_id}\", (bbox_xmin, bbox_ymin - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, track_color, 2)\n",
        "\n",
        "    # 7f. Write the annotated frame to the output video\n",
        "    out.write(annotated_frame)\n",
        "\n",
        "    frame_count += 1\n",
        "    if frame_count % 100 == 0:\n",
        "        print(f\"Processed {frame_count} frames...\")\n",
        "\n",
        "# 8. Release the video capture and writer objects\n",
        "video_cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# 9. Print a message indicating completion\n",
        "print(\"Video processing complete with DeepSORT. Output saved.\")\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing video: input_video.mp4 with DeepSORT\n",
            "Output video will be saved to: output_video_deepsort.mp4\n",
            "\n",
            "0: 384x640 1 person, 7.5ms\n",
            "Speed: 1.7ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.9ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 1.7ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 2.0ms preprocess, 6.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 2.0ms preprocess, 6.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.1ms\n",
            "Speed: 1.8ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 1.6ms preprocess, 8.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.7ms preprocess, 5.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.8ms\n",
            "Speed: 2.1ms preprocess, 6.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.8ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.9ms preprocess, 5.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.4ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 2.1ms preprocess, 6.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.6ms\n",
            "Speed: 1.7ms preprocess, 6.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.1ms\n",
            "Speed: 1.8ms preprocess, 7.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.1ms\n",
            "Speed: 1.9ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.2ms\n",
            "Speed: 2.1ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.0ms\n",
            "Speed: 1.8ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.1ms\n",
            "Speed: 2.0ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.0ms\n",
            "Speed: 1.9ms preprocess, 7.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 1.7ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.9ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.8ms\n",
            "Speed: 2.0ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.4ms\n",
            "Speed: 1.7ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 2.0ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.2ms\n",
            "Speed: 2.0ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.9ms\n",
            "Speed: 1.8ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 1.8ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.5ms\n",
            "Speed: 1.9ms preprocess, 7.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.2ms\n",
            "Speed: 2.1ms preprocess, 7.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.1ms\n",
            "Speed: 1.9ms preprocess, 7.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.1ms\n",
            "Speed: 2.0ms preprocess, 7.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.9ms\n",
            "Speed: 2.0ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.2ms\n",
            "Speed: 2.0ms preprocess, 8.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.7ms\n",
            "Speed: 1.7ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.9ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.1ms\n",
            "Speed: 2.0ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.8ms\n",
            "Speed: 1.8ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.9ms\n",
            "Speed: 1.9ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.7ms\n",
            "Speed: 2.0ms preprocess, 6.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 2.2ms preprocess, 9.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.1ms preprocess, 9.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.1ms\n",
            "Speed: 2.2ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.0ms\n",
            "Speed: 2.1ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 2.2ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 2.1ms preprocess, 6.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 2.0ms preprocess, 6.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.9ms\n",
            "Speed: 1.7ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.5ms\n",
            "Speed: 2.2ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 1.8ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 1.9ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 2.1ms preprocess, 6.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 2.0ms preprocess, 6.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.3ms\n",
            "Speed: 2.0ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 2.2ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.4ms\n",
            "Speed: 2.2ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 2.1ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 1.7ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.6ms\n",
            "Speed: 1.9ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 2.0ms preprocess, 6.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 2.1ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 2.0ms preprocess, 6.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 1.9ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 2.0ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.7ms\n",
            "Speed: 2.2ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.5ms\n",
            "Speed: 2.1ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 1.7ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 2.1ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 1.7ms preprocess, 6.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 2.1ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.3ms\n",
            "Speed: 2.5ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.5ms\n",
            "Speed: 2.3ms preprocess, 10.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.2ms preprocess, 9.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.5ms\n",
            "Speed: 1.7ms preprocess, 6.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.4ms\n",
            "Speed: 2.2ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.1ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.2ms\n",
            "Speed: 2.1ms preprocess, 7.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.8ms\n",
            "Speed: 1.9ms preprocess, 6.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.2ms\n",
            "Speed: 2.0ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed 100 frames...\n",
            "\n",
            "0: 384x640 1 person, 6.5ms\n",
            "Speed: 1.8ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.8ms preprocess, 6.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.8ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.5ms\n",
            "Speed: 1.9ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.8ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.7ms\n",
            "Speed: 1.9ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.5ms\n",
            "Speed: 1.8ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.8ms\n",
            "Speed: 1.8ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.6ms\n",
            "Speed: 2.1ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 2.0ms preprocess, 6.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.5ms\n",
            "Speed: 1.9ms preprocess, 6.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.9ms\n",
            "Speed: 2.0ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.3ms\n",
            "Speed: 1.9ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.3ms\n",
            "Speed: 1.8ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.3ms\n",
            "Speed: 2.0ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.0ms\n",
            "Speed: 1.7ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.2ms\n",
            "Speed: 2.1ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.3ms\n",
            "Speed: 1.7ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.3ms\n",
            "Speed: 2.0ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.7ms\n",
            "Speed: 2.0ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 1.9ms preprocess, 6.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.7ms\n",
            "Speed: 2.8ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.0ms\n",
            "Speed: 2.0ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.4ms\n",
            "Speed: 2.1ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.3ms\n",
            "Speed: 2.3ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 1.8ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.9ms preprocess, 6.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.7ms\n",
            "Speed: 2.0ms preprocess, 6.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 1.9ms preprocess, 6.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.5ms\n",
            "Speed: 1.8ms preprocess, 6.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.7ms\n",
            "Speed: 1.7ms preprocess, 6.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.6ms\n",
            "Speed: 2.0ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 2.1ms preprocess, 8.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 1.9ms preprocess, 6.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.5ms\n",
            "Speed: 2.0ms preprocess, 6.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.0ms\n",
            "Speed: 2.2ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.2ms\n",
            "Speed: 1.9ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.8ms preprocess, 6.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.8ms preprocess, 5.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.8ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.1ms\n",
            "Speed: 2.0ms preprocess, 7.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 2.1ms preprocess, 5.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.4ms\n",
            "Speed: 1.8ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.5ms\n",
            "Speed: 1.9ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.9ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.8ms preprocess, 5.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.8ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.9ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.8ms preprocess, 6.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.5ms\n",
            "Speed: 1.8ms preprocess, 6.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.3ms\n",
            "Speed: 1.6ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.5ms\n",
            "Speed: 1.8ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed 200 frames...\n",
            "\n",
            "0: 384x640 2 persons, 6.9ms\n",
            "Speed: 2.0ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 2.0ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.6ms\n",
            "Speed: 1.8ms preprocess, 6.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.5ms\n",
            "Speed: 1.9ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 6.3ms\n",
            "Speed: 1.8ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.4ms\n",
            "Speed: 1.9ms preprocess, 6.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.0ms\n",
            "Speed: 1.7ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.7ms\n",
            "Speed: 1.7ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.9ms\n",
            "Speed: 1.7ms preprocess, 6.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.2ms\n",
            "Speed: 1.8ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 1.8ms preprocess, 6.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.9ms\n",
            "Speed: 1.9ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.9ms\n",
            "Speed: 1.8ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.9ms\n",
            "Speed: 2.0ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.6ms\n",
            "Speed: 1.7ms preprocess, 6.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.7ms\n",
            "Speed: 1.9ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.6ms\n",
            "Speed: 1.8ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.6ms\n",
            "Speed: 2.0ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 1.8ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.9ms preprocess, 6.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.0ms\n",
            "Speed: 1.8ms preprocess, 6.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.9ms preprocess, 6.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.2ms\n",
            "Speed: 1.8ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.9ms preprocess, 6.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 1.7ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.9ms preprocess, 6.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 1.7ms preprocess, 6.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.8ms preprocess, 6.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 1.7ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.8ms\n",
            "Speed: 1.9ms preprocess, 6.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.4ms\n",
            "Speed: 1.6ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 2.0ms preprocess, 6.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.5ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.8ms preprocess, 6.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 1.8ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.7ms preprocess, 5.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 2.0ms preprocess, 5.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 1.9ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.8ms\n",
            "Speed: 1.6ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.5ms\n",
            "Speed: 1.6ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.5ms preprocess, 6.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.8ms preprocess, 6.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.5ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.4ms preprocess, 5.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.3ms\n",
            "Speed: 1.8ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 2.0ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.8ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.6ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.5ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 1.7ms preprocess, 6.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.5ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.5ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.8ms preprocess, 6.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed 300 frames...\n",
            "\n",
            "0: 384x640 2 persons, 6.0ms\n",
            "Speed: 1.8ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.8ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.8ms preprocess, 5.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.4ms\n",
            "Speed: 1.6ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.5ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 1.6ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.5ms preprocess, 6.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.8ms preprocess, 6.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.6ms preprocess, 6.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.8ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.3ms\n",
            "Speed: 2.0ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.9ms preprocess, 6.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 1.5ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.9ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.8ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.3ms\n",
            "Speed: 1.8ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.3ms\n",
            "Speed: 1.6ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.9ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.8ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.8ms\n",
            "Speed: 1.7ms preprocess, 6.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.9ms\n",
            "Speed: 1.8ms preprocess, 6.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.5ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Video processing complete with DeepSORT. Output saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5bee3f3"
      },
      "source": [
        "The next code block is similar to the last one but here we are analyzing the tracking data.It will collect all our tracking data and make it into a list.\n",
        "\n",
        "As you can see the end section of\n",
        "\n",
        "TRACKING ANALLYSIS RESULTS\n",
        "which gives us the total uniqe id's/ people it detected in the video.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "035451e1",
        "outputId": "e067b72d-ce32-4211-8dc0-5049a55f3cd6"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "import pandas as pd\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "\n",
        "# 1. Re-initialize the DeepSort tracker and load the YOLOv8 model\n",
        "tracker = DeepSort(max_iou_distance=0.8, max_age=10, n_init=3) # Adjusted parameters\n",
        "model = YOLO('yolov8n.pt')  # Using 'yolov8n.pt' for its balance of speed and accuracy\n",
        "\n",
        "# Define input and output video paths\n",
        "input_video_path = 'input_video.mp4'\n",
        "output_video_path_analysis = 'output_video_deepsort_analysis.mp4'\n",
        "\n",
        "# 2. Create an empty list to store tracking information\n",
        "tracking_results_data = []\n",
        "\n",
        "# Open the video file\n",
        "video_cap = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "# Get video properties\n",
        "frame_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Codec for .mp4\n",
        "out = cv2.VideoWriter(output_video_path_analysis, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "print(f\"Processing video for data collection: {input_video_path}\")\n",
        "print(f\"Output video with annotations will be saved to: {output_video_path_analysis}\")\n",
        "\n",
        "frame_count = 0\n",
        "while video_cap.isOpened():\n",
        "    ret, frame = video_cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 4a. Perform object detection using the pre-loaded YOLOv8 model\n",
        "    # Only detect 'person' class (class ID 0 in COCO dataset)\n",
        "    results = model.predict(frame, classes=[0], conf=0.5, iou=0.5)\n",
        "\n",
        "    detections = []\n",
        "    if results[0].boxes is not None:\n",
        "        # 4b. Extract bounding boxes (xmin, ymin, xmax, ymax) and confidence scores\n",
        "        # Convert bounding box coordinates to the format expected by DeepSORT (top-left x, top-left y, width, height)\n",
        "        for box in results[0].boxes.data:\n",
        "            xmin, ymin, xmax, ymax, conf, class_id = box.tolist()\n",
        "            w = xmax - xmin\n",
        "            h = ymax - ymin\n",
        "            detections.append(([xmin, ymin, w, h], conf, class_id))\n",
        "\n",
        "    # 4c. Update the DeepSORT tracker\n",
        "    tracks = tracker.update_tracks(detections, frame=frame) # Pass frame for appearance feature extraction if enabled in DeepSort\n",
        "\n",
        "    annotated_frame = frame.copy()\n",
        "\n",
        "    # 4d. Iterate through the updated tracks and record data\n",
        "    for track in tracks:\n",
        "        if not track.is_confirmed():\n",
        "            continue\n",
        "\n",
        "        track_id = track.track_id\n",
        "        ltrb = track.to_ltrb()\n",
        "\n",
        "        # Record tracking data\n",
        "        tracking_results_data.append({\n",
        "            'frame_count': frame_count,\n",
        "            'track_id': track_id,\n",
        "            'bbox_xmin': ltrb[0],\n",
        "            'bbox_ymin': ltrb[1],\n",
        "            'bbox_xmax': ltrb[2],\n",
        "            'bbox_ymax': ltrb[3]\n",
        "        })\n",
        "\n",
        "        # 4e. Draw bounding box\n",
        "        color_seed = int(str(hash(track_id))[-3:]) # Use last 3 digits of hash for color variation\n",
        "        b = (color_seed * 17) % 255\n",
        "        g = (color_seed * 37) % 255\n",
        "        r = (color_seed * 53) % 255\n",
        "        track_color = (b, g, r)\n",
        "\n",
        "        bbox_xmin, bbox_ymin, bbox_xmax, bbox_ymax = int(ltrb[0]), int(ltrb[1]), int(ltrb[2]), int(ltrb[3])\n",
        "        cv2.rectangle(annotated_frame, (bbox_xmin, bbox_ymin), (bbox_xmax, bbox_ymax), track_color, 2)\n",
        "        cv2.putText(annotated_frame, f\"ID: {track_id}\", (bbox_xmin, bbox_ymin - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, track_color, 2)\n",
        "\n",
        "    # 4f. Write the annotated frame to the output video\n",
        "    out.write(annotated_frame)\n",
        "\n",
        "    frame_count += 1\n",
        "    if frame_count % 100 == 0:\n",
        "        print(f\"Processed {frame_count} frames...\")\n",
        "\n",
        "# 5. Release the video capture and writer objects\n",
        "video_cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(\"Video processing and data collection complete. Now analyzing tracking data.\")\n",
        "\n",
        "# 6. Convert the tracking_results_data list into a Pandas DataFrame\n",
        "tracking_df = pd.DataFrame(tracking_results_data)\n",
        "\n",
        "# 7. Calculate the total number of unique track_id values\n",
        "total_unique_ids = tracking_df['track_id'].nunique()\n",
        "\n",
        "# 8. For each unique track_id, count how many frames it appeared in to determine its track length.\n",
        "# Then, calculate the average of these track lengths.\n",
        "if not tracking_df.empty:\n",
        "    track_lengths = tracking_df.groupby('track_id')['frame_count'].nunique()\n",
        "    average_track_length = track_lengths.mean()\n",
        "else:\n",
        "    track_lengths = pd.Series()\n",
        "    average_track_length = 0\n",
        "\n",
        "# 9. Print the statistics\n",
        "print(f\"\\n--- Tracking Analysis Results ---\")\n",
        "print(f\"Total number of unique track IDs: {total_unique_ids}\")\n",
        "print(f\"Average track length (number of frames an ID appeared): {average_track_length:.2f} frames\")\n",
        "print(\"Quantitative assessment of identity switches and fragmentation often requires more complex metrics or qualitative review, which will be addressed in a later step.\")"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing video for data collection: input_video.mp4\n",
            "Output video with annotations will be saved to: output_video_deepsort_analysis.mp4\n",
            "\n",
            "0: 384x640 1 person, 7.6ms\n",
            "Speed: 1.8ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.5ms preprocess, 5.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.5ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.5ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.5ms preprocess, 6.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 1.6ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.8ms\n",
            "Speed: 1.4ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.5ms\n",
            "Speed: 1.7ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.7ms\n",
            "Speed: 1.7ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.9ms\n",
            "Speed: 1.7ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.8ms\n",
            "Speed: 1.7ms preprocess, 6.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.8ms\n",
            "Speed: 1.7ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.9ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.5ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.9ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 1.6ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.5ms preprocess, 5.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.4ms\n",
            "Speed: 1.5ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.8ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.5ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.5ms preprocess, 6.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 1.8ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.6ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 2.1ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.8ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.8ms\n",
            "Speed: 1.7ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.8ms preprocess, 6.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.8ms\n",
            "Speed: 1.9ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.6ms preprocess, 6.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 1.8ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.5ms preprocess, 6.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.5ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.5ms preprocess, 6.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.5ms\n",
            "Speed: 1.8ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 1.9ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 1.8ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed 100 frames...\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.5ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.9ms preprocess, 6.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.5ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.6ms preprocess, 6.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.7ms preprocess, 5.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.5ms preprocess, 6.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.5ms preprocess, 5.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.6ms\n",
            "Speed: 2.2ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 1.8ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.5ms\n",
            "Speed: 1.8ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.7ms\n",
            "Speed: 1.7ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.9ms preprocess, 6.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.5ms preprocess, 6.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.2ms\n",
            "Speed: 1.9ms preprocess, 7.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.6ms\n",
            "Speed: 1.9ms preprocess, 7.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.7ms\n",
            "Speed: 1.7ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.7ms\n",
            "Speed: 1.8ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.9ms\n",
            "Speed: 1.6ms preprocess, 6.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 1.5ms preprocess, 6.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.4ms\n",
            "Speed: 1.7ms preprocess, 7.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.9ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.1ms\n",
            "Speed: 1.5ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.7ms\n",
            "Speed: 1.9ms preprocess, 6.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.9ms preprocess, 6.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.4ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 1.7ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 1.8ms preprocess, 6.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.8ms\n",
            "Speed: 1.7ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.9ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 1.5ms preprocess, 5.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.5ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.5ms preprocess, 6.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.1ms\n",
            "Speed: 1.5ms preprocess, 6.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.4ms\n",
            "Speed: 1.5ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.8ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.5ms preprocess, 6.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.0ms\n",
            "Speed: 1.8ms preprocess, 7.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 1.8ms preprocess, 5.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.5ms\n",
            "Speed: 1.7ms preprocess, 6.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.4ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.4ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.4ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.5ms preprocess, 6.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.5ms preprocess, 5.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 1.6ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.9ms\n",
            "Speed: 1.4ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.4ms preprocess, 6.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.8ms preprocess, 6.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.5ms preprocess, 6.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.4ms preprocess, 6.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.4ms preprocess, 5.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.8ms\n",
            "Speed: 1.7ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.8ms\n",
            "Speed: 1.8ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.6ms\n",
            "Speed: 1.6ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed 200 frames...\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.9ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.2ms\n",
            "Speed: 2.1ms preprocess, 6.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.5ms\n",
            "Speed: 1.9ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.7ms\n",
            "Speed: 2.0ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.0ms\n",
            "Speed: 1.7ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.6ms\n",
            "Speed: 1.7ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.1ms\n",
            "Speed: 1.5ms preprocess, 6.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 6.5ms\n",
            "Speed: 2.1ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.2ms\n",
            "Speed: 1.5ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.6ms\n",
            "Speed: 1.8ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 1.9ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.9ms\n",
            "Speed: 2.0ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.0ms\n",
            "Speed: 1.8ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 2.1ms preprocess, 6.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.6ms\n",
            "Speed: 1.7ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.0ms\n",
            "Speed: 1.9ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.0ms\n",
            "Speed: 1.8ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.3ms\n",
            "Speed: 1.7ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.0ms\n",
            "Speed: 1.9ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.3ms\n",
            "Speed: 2.0ms preprocess, 6.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 2.0ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.2ms\n",
            "Speed: 1.9ms preprocess, 6.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.2ms\n",
            "Speed: 1.5ms preprocess, 6.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.1ms\n",
            "Speed: 2.0ms preprocess, 6.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.3ms\n",
            "Speed: 1.8ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.9ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 1.9ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 1.9ms preprocess, 6.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 1.8ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.8ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.6ms preprocess, 6.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.8ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.9ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 2.0ms preprocess, 6.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 1.7ms preprocess, 6.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.9ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.2ms\n",
            "Speed: 1.9ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.8ms\n",
            "Speed: 1.8ms preprocess, 6.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.7ms\n",
            "Speed: 1.7ms preprocess, 6.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.7ms\n",
            "Speed: 1.8ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.8ms\n",
            "Speed: 1.7ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.7ms\n",
            "Speed: 2.0ms preprocess, 6.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.8ms preprocess, 6.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 2.0ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 2.0ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 1.7ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 2.1ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 2.0ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.9ms\n",
            "Speed: 1.7ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.3ms\n",
            "Speed: 1.8ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 1.8ms preprocess, 6.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.8ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.8ms\n",
            "Speed: 1.6ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.5ms\n",
            "Speed: 2.1ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.8ms\n",
            "Speed: 1.8ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.9ms\n",
            "Speed: 2.1ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.8ms preprocess, 6.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.8ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.8ms preprocess, 6.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.0ms\n",
            "Speed: 2.0ms preprocess, 7.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.4ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 1.9ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 1.7ms preprocess, 6.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.8ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 1.7ms preprocess, 5.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed 300 frames...\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.8ms\n",
            "Speed: 1.5ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.4ms preprocess, 5.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.0ms\n",
            "Speed: 1.8ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.3ms\n",
            "Speed: 1.6ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.4ms preprocess, 5.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 1.8ms preprocess, 6.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.8ms preprocess, 5.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.8ms preprocess, 5.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.9ms preprocess, 6.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.5ms preprocess, 6.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.9ms preprocess, 6.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.8ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.7ms preprocess, 5.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 2.0ms preprocess, 6.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 1.6ms preprocess, 6.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.8ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 2.0ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 2.1ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.4ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.6ms\n",
            "Speed: 1.7ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 1.8ms preprocess, 6.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.8ms preprocess, 6.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Video processing and data collection complete. Now analyzing tracking data.\n",
            "\n",
            "--- Tracking Analysis Results ---\n",
            "Total number of unique track IDs: 25\n",
            "Average track length (number of frames an ID appeared): 19.20 frames\n",
            "Quantitative assessment of identity switches and fragmentation often requires more complex metrics or qualitative review, which will be addressed in a later step.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "079b52d4"
      },
      "source": [
        "## Calculate Centroid Coordinates\n",
        "\n",
        "This code block is calculating the center coordinates of each bounding box for every tracked person and adding these as new columns to the tracking_df. This in general makes it easier to analyze our boxes movement within the video."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7568afef",
        "outputId": "e5f8e337-b45c-4aec-feb0-5b318f841168"
      },
      "source": [
        "tracking_df['center_x'] = (tracking_df['bbox_xmin'] + tracking_df['bbox_xmax']) / 2\n",
        "tracking_df['center_y'] = (tracking_df['bbox_ymin'] + tracking_df['bbox_ymax']) / 2\n",
        "\n",
        "print(\"Added 'center_x' and 'center_y' columns to tracking_df.\")\n",
        "print(tracking_df.head())"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 'center_x' and 'center_y' columns to tracking_df.\n",
            "   frame_count track_id   bbox_xmin   bbox_ymin   bbox_xmax   bbox_ymax  \\\n",
            "0            2        1  449.403569  424.812202  496.096174  554.239093   \n",
            "1            3        1  450.018919  421.848193  496.386314  550.373637   \n",
            "2            4        1  450.634269  418.884184  496.676454  546.508182   \n",
            "3            5        1  451.249619  415.920176  496.966594  542.642726   \n",
            "4            6        1  451.864969  412.956167  497.256735  538.777271   \n",
            "\n",
            "     center_x    center_y  \n",
            "0  472.749872  489.525648  \n",
            "1  473.202617  486.110915  \n",
            "2  473.655362  482.696183  \n",
            "3  474.108107  479.281451  \n",
            "4  474.560852  475.866719  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaada900"
      },
      "source": [
        "## Generate Tracking Path Plot\n",
        "\n",
        "Here we visualize our tracking dataframe which allows you to see the paths of your bounding boxes in this case, the people in our video.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "id": "1a48a17f",
        "outputId": "2e3d0b16-41e5-4296-ae1a-3a239d1c1f7b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a figure and an axes object for the plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Get all unique track_ids\n",
        "unique_track_ids = tracking_df['track_id'].unique()\n",
        "\n",
        "# Iterate through each unique track_id and plot its path\n",
        "for track_id in unique_track_ids:\n",
        "    track_data = tracking_df[tracking_df['track_id'] == track_id].sort_values(by='frame_count')\n",
        "    plt.plot(track_data['center_x'], track_data['center_y'], label=f'Track {track_id}')\n",
        "\n",
        "# Add appropriate labels and title\n",
        "plt.xlabel('Center X Coordinate')\n",
        "plt.ylabel('Center Y Coordinate')\n",
        "plt.title('Human Tracking Paths Over Time')\n",
        "\n",
        "# Add a legend\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.grid(True)\n",
        "plt.tight_layout() # Adjust layout to prevent labels from overlapping\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "print(\"Tracking paths plot generated successfully.\")"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tracking paths plot generated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This next code block will processes your video, perform object detection and multi-object tracking, collects detailed data about each tracked individual's position and detection confidence, annotates the video with this information, saves the annotated video, and then provides a basic statistical overview of the tracking results. The explicit confidence score capture and display were added to address your request about 'accuracy' visualization."
      ],
      "metadata": {
        "id": "QlbIEmwov6J_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cacce58a",
        "outputId": "d4a53641-a23a-4af7-8d30-7799dfd0b047"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "import pandas as pd\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "\n",
        "# 1. Re-initialize the DeepSort tracker and load the YOLOv8 model\n",
        "tracker = DeepSort(max_iou_distance=0.8, max_age=10, n_init=3) # Adjusted parameters\n",
        "model = YOLO('yolov8n.pt')  # Using 'yolov8n.pt' for its balance of speed and accuracy\n",
        "\n",
        "# Define input and output video paths\n",
        "input_video_path = 'input_video.mp4'\n",
        "output_video_path_analysis = 'output_video_deepsort_analysis.mp4'\n",
        "\n",
        "# 2. Create an empty list to store tracking information\n",
        "tracking_results_data = []\n",
        "\n",
        "# Open the video file\n",
        "video_cap = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "# Get video properties\n",
        "frame_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Codec for .mp4\n",
        "out = cv2.VideoWriter(output_video_path_analysis, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "print(f\"Processing video for data collection: {input_video_path}\")\n",
        "print(f\"Output video with annotations will be saved to: {output_video_path_analysis}\")\n",
        "\n",
        "frame_count = 0\n",
        "while video_cap.isOpened():\n",
        "    ret, frame = video_cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 4a. Perform object detection using the pre-loaded YOLOv8 model\n",
        "    # Only detect 'person' class (class ID 0 in COCO dataset)\n",
        "    results = model.predict(frame, classes=[0], conf=0.5, iou=0.5)\n",
        "\n",
        "    detections = []\n",
        "    if results[0].boxes is not None:\n",
        "        # 4b. Extract bounding boxes (xmin, ymin, xmax, ymax) and confidence scores\n",
        "        # Convert bounding box coordinates to the format expected by DeepSORT (top-left x, top-left y, width, height)\n",
        "        for box in results[0].boxes.data:\n",
        "            xmin, ymin, xmax, ymax, conf, class_id = box.tolist()\n",
        "            w = xmax - xmin\n",
        "            h = ymax - ymin\n",
        "            detections.append(([xmin, ymin, w, h], conf, class_id))\n",
        "\n",
        "    # 4c. Update the DeepSORT tracker\n",
        "    tracks = tracker.update_tracks(detections, frame=frame) # Pass frame for appearance feature extraction if enabled in DeepSort\n",
        "\n",
        "    annotated_frame = frame.copy()\n",
        "\n",
        "    # 4d. Iterate through the updated tracks and record data\n",
        "    for track in tracks:\n",
        "        if not track.is_confirmed():\n",
        "            continue\n",
        "\n",
        "        track_id = track.track_id\n",
        "        ltrb = track.to_ltrb()\n",
        "\n",
        "        # Record tracking data, including confidence score\n",
        "        # DeepSORT tracks do not directly expose the confidence score from the initial detection\n",
        "        # for a given frame after being tracked. To capture a 'confidence' for a tracked object,\n",
        "        # we would typically associate it with the confidence of the detection that initiated/updated the track.\n",
        "        # However, for simplicity and based on the instruction to use the 'conf' variable from detection,\n",
        "        # we'll store the maximum confidence of any detection associated with this track in the current frame.\n",
        "        # This requires matching detections to tracks, which deep_sort_realtime does internally.\n",
        "        # For this specific implementation, I will assume the `conf` from the detection used to update the track\n",
        "        # is the relevant one. Since `detections` is built from `results[0].boxes.data` which includes `conf`,\n",
        "        # I'll modify `detections.append` to store `conf` directly and then extract it.\n",
        "\n",
        "        # Re-iterating through results to find the confidence for the current track_id's bounding box\n",
        "        # This is a simplification. A more robust approach would be to store detection confidences\n",
        "        # within the DeepSort object or directly associate them during the track update phase.\n",
        "        # Given the instruction is to use the `conf` variable, I'll extract it from `detections`.\n",
        "        current_frame_detection_conf = 0.0\n",
        "        for det_bbox, det_conf, det_class_id in detections:\n",
        "            # Simple check if detection box overlaps significantly with track's current bbox\n",
        "            # A more robust check would involve comparing track_id from DeepSort with original detection ID,\n",
        "            # but deep_sort_realtime doesn't directly return detection IDs associated with tracks.\n",
        "            # For this task, we will just use the general confidence 'conf' from the initial detection parsing.\n",
        "            # We'll use the 'conf' variable directly from the loop when appending to ensure it's captured.\n",
        "            pass # This pass is just to note that `conf` is available from the `detections` list.\n",
        "\n",
        "        # The `conf` variable inside the detections loop refers to the confidence of the detection\n",
        "        # that was just processed. When we add it to `tracking_results_data`, it will be the `conf`\n",
        "        # corresponding to the last detection that matched the track in that frame (if multiple were present)\n",
        "        # or simply the detection that created/updated the track. Assuming `conf` is passed properly.\n",
        "\n",
        "        # To correctly get the `conf` for the current `track` being processed, we need to match\n",
        "        # the DeepSort track's bounding box to one of the raw YOLO detections (or the detection\n",
        "        # that contributed to this track). As DeepSort doesn't return the original detection ID,\n",
        "        # a direct mapping is not straightforward without modifying DeepSort's internals or post-processing.\n",
        "        # For this task, I will capture the `conf` from the `detections` list if it corresponds to the `ltrb`\n",
        "        # of the current track, by checking bounding box overlap. If multiple, take the highest confidence.\n",
        "        best_conf_for_track = 0.0\n",
        "        for det_box_xywh, det_conf, det_class_id in detections:\n",
        "            # Convert detection (x,y,w,h) to (xmin, ymin, xmax, ymax) for comparison\n",
        "            det_xmin, det_ymin, det_w, det_h = det_box_xywh\n",
        "            det_xmax = det_xmin + det_w\n",
        "            det_ymax = det_ymin + det_h\n",
        "            det_ltrb = [det_xmin, det_ymin, det_xmax, det_ymax]\n",
        "\n",
        "            # Calculate IoU or simple overlap to match detection to track\n",
        "            # A simple overlap check to see if the detection corresponds to the track\n",
        "            # This is not a perfect mapping but serves to associate a confidence.\n",
        "            intersection_xmin = max(ltrb[0], det_ltrb[0])\n",
        "            intersection_ymin = max(ltrb[1], det_ltrb[1])\n",
        "            intersection_xmax = min(ltrb[2], det_ltrb[2])\n",
        "            intersection_ymax = min(ltrb[3], det_ltrb[3])\n",
        "\n",
        "            if intersection_xmax > intersection_xmin and intersection_ymax > intersection_ymin:\n",
        "                intersection_area = (intersection_xmax - intersection_xmin) * (intersection_ymax - intersection_ymin)\n",
        "                track_area = (ltrb[2] - ltrb[0]) * (ltrb[3] - ltrb[1])\n",
        "                det_area = det_w * det_h\n",
        "                union_area = track_area + det_area - intersection_area\n",
        "                iou = intersection_area / union_area if union_area > 0 else 0\n",
        "\n",
        "                if iou > 0.5: # If there's significant overlap, consider it a match\n",
        "                    if det_conf > best_conf_for_track:\n",
        "                        best_conf_for_track = det_conf\n",
        "\n",
        "        tracking_results_data.append({\n",
        "            'frame_count': frame_count,\n",
        "            'track_id': track_id,\n",
        "            'bbox_xmin': ltrb[0],\n",
        "            'bbox_ymin': ltrb[1],\n",
        "            'bbox_xmax': ltrb[2],\n",
        "            'bbox_ymax': ltrb[3],\n",
        "            'confidence': best_conf_for_track # Added confidence here\n",
        "        })\n",
        "\n",
        "        # 4e. Draw bounding box\n",
        "        color_seed = int(str(hash(track_id))[-3:]) # Use last 3 digits of hash for color variation\n",
        "        b = (color_seed * 17) % 255\n",
        "        g = (color_seed * 37) % 255\n",
        "        r = (color_seed * 53) % 255\n",
        "        track_color = (b, g, r)\n",
        "\n",
        "        bbox_xmin, bbox_ymin, bbox_xmax, bbox_ymax = int(ltrb[0]), int(ltrb[1]), int(ltrb[2]), int(ltrb[3])\n",
        "        cv2.rectangle(annotated_frame, (bbox_xmin, bbox_ymin), (bbox_xmax, bbox_ymax), track_color, 2)\n",
        "        cv2.putText(annotated_frame, f\"ID: {track_id} C:{best_conf_for_track:.2f}\", (bbox_xmin, bbox_ymin - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, track_color, 2)\n",
        "\n",
        "    # 4f. Write the annotated frame to the output video\n",
        "    out.write(annotated_frame)\n",
        "\n",
        "    frame_count += 1\n",
        "    if frame_count % 100 == 0:\n",
        "        print(f\"Processed {frame_count} frames...\")\n",
        "\n",
        "# 5. Release the video capture and writer objects\n",
        "video_cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(\"Video processing and data collection complete. Now analyzing tracking data.\")\n",
        "\n",
        "# 6. Convert the tracking_results_data list into a Pandas DataFrame\n",
        "tracking_df = pd.DataFrame(tracking_results_data)\n",
        "\n",
        "# 7. Calculate the total number of unique track_id values\n",
        "total_unique_ids = tracking_df['track_id'].nunique()\n",
        "\n",
        "# 8. For each unique track_id, count how many frames it appeared in to determine its track length.\n",
        "# Then, calculate the average of these track lengths.\n",
        "if not tracking_df.empty:\n",
        "    track_lengths = tracking_df.groupby('track_id')['frame_count'].nunique()\n",
        "    average_track_length = track_lengths.mean()\n",
        "else:\n",
        "    track_lengths = pd.Series()\n",
        "    average_track_length = 0\n",
        "\n",
        "# 9. Print the statistics\n",
        "print(f\"\\n--- Tracking Analysis Results ---\")\n",
        "print(f\"Total number of unique track IDs: {total_unique_ids}\")\n",
        "print(f\"Average track length (number of frames an ID appeared): {average_track_length:.2f} frames\")\n",
        "print(\"Quantitative assessment of identity switches and fragmentation often requires more complex metrics or qualitative review, which will be addressed in a later step.\")"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing video for data collection: input_video.mp4\n",
            "Output video with annotations will be saved to: output_video_deepsort_analysis.mp4\n",
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 2.2ms preprocess, 13.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 1.8ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.3ms\n",
            "Speed: 1.8ms preprocess, 7.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.6ms\n",
            "Speed: 2.1ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 2.0ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.5ms\n",
            "Speed: 2.1ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.4ms\n",
            "Speed: 2.1ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.4ms\n",
            "Speed: 2.2ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.9ms\n",
            "Speed: 1.8ms preprocess, 6.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.8ms preprocess, 6.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.5ms\n",
            "Speed: 1.8ms preprocess, 6.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.9ms preprocess, 5.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.7ms\n",
            "Speed: 1.8ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 2.0ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.4ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 1.5ms preprocess, 5.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.2ms\n",
            "Speed: 1.5ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.1ms\n",
            "Speed: 1.5ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.0ms\n",
            "Speed: 2.0ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.6ms\n",
            "Speed: 1.9ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.9ms preprocess, 6.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.0ms\n",
            "Speed: 2.2ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.0ms\n",
            "Speed: 1.8ms preprocess, 6.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.8ms\n",
            "Speed: 1.5ms preprocess, 5.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.7ms\n",
            "Speed: 1.8ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.5ms\n",
            "Speed: 2.0ms preprocess, 6.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 1.9ms preprocess, 5.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.9ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 2.0ms preprocess, 5.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.0ms\n",
            "Speed: 2.3ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.5ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.9ms\n",
            "Speed: 1.7ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 1.6ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.6ms\n",
            "Speed: 1.9ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.3ms\n",
            "Speed: 1.8ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.8ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.8ms preprocess, 6.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.8ms preprocess, 5.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.8ms preprocess, 6.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.5ms preprocess, 6.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 1.6ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.0ms\n",
            "Speed: 2.2ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 1.7ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 2.0ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 2.2ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.7ms\n",
            "Speed: 2.2ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.3ms\n",
            "Speed: 2.0ms preprocess, 7.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.7ms\n",
            "Speed: 1.9ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.6ms\n",
            "Speed: 1.8ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.0ms\n",
            "Speed: 2.0ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.5ms\n",
            "Speed: 2.0ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 2.0ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 2.1ms preprocess, 6.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 1.7ms preprocess, 6.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed 100 frames...\n",
            "\n",
            "0: 384x640 1 person, 9.3ms\n",
            "Speed: 2.0ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 1.9ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.6ms\n",
            "Speed: 1.9ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.1ms\n",
            "Speed: 1.9ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.6ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 1.6ms preprocess, 6.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.7ms\n",
            "Speed: 2.1ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.6ms\n",
            "Speed: 2.0ms preprocess, 7.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 1.5ms preprocess, 5.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.4ms preprocess, 5.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 1.5ms preprocess, 5.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.5ms preprocess, 6.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.5ms preprocess, 6.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.5ms preprocess, 5.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.6ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 1.6ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 1.7ms preprocess, 6.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 1.5ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 1.8ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.9ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.8ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.8ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.8ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.8ms preprocess, 5.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.5ms preprocess, 5.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.4ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.5ms preprocess, 5.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 2.0ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.8ms preprocess, 5.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.8ms\n",
            "Speed: 1.7ms preprocess, 5.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 1.7ms preprocess, 5.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.9ms\n",
            "Speed: 1.8ms preprocess, 6.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.5ms\n",
            "Speed: 1.9ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.7ms\n",
            "Speed: 1.7ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.5ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 1.7ms preprocess, 5.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.5ms preprocess, 5.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.8ms preprocess, 5.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.8ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.5ms\n",
            "Speed: 1.5ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 1.8ms preprocess, 6.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.1ms\n",
            "Speed: 1.5ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 2.0ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.4ms\n",
            "Speed: 1.8ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed 200 frames...\n",
            "\n",
            "0: 384x640 2 persons, 6.2ms\n",
            "Speed: 2.1ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.7ms\n",
            "Speed: 1.7ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.0ms\n",
            "Speed: 1.7ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.0ms\n",
            "Speed: 2.0ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.9ms\n",
            "Speed: 1.8ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 2.0ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.8ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5.9ms\n",
            "Speed: 1.8ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.4ms\n",
            "Speed: 2.0ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.6ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.0ms\n",
            "Speed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.5ms preprocess, 6.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.9ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.5ms preprocess, 6.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.9ms preprocess, 5.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.2ms\n",
            "Speed: 1.5ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.9ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5.8ms\n",
            "Speed: 1.5ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.9ms\n",
            "Speed: 1.7ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.8ms\n",
            "Speed: 1.7ms preprocess, 5.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.5ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.8ms\n",
            "Speed: 1.8ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.8ms\n",
            "Speed: 1.8ms preprocess, 5.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 1.7ms preprocess, 5.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 2.0ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.8ms preprocess, 6.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.5ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.8ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.8ms preprocess, 6.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.8ms preprocess, 6.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.9ms\n",
            "Speed: 1.6ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 1.8ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.7ms\n",
            "Speed: 1.8ms preprocess, 6.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 1.8ms preprocess, 6.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.8ms preprocess, 5.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.3ms\n",
            "Speed: 1.8ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.9ms preprocess, 6.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.9ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.5ms preprocess, 5.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5.9ms\n",
            "Speed: 1.9ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.7ms preprocess, 5.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.0ms\n",
            "Speed: 2.0ms preprocess, 7.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.8ms\n",
            "Speed: 1.7ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.8ms\n",
            "Speed: 1.9ms preprocess, 6.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 1.7ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.8ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.7ms preprocess, 5.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 1.4ms preprocess, 6.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.7ms preprocess, 5.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 1.7ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.5ms preprocess, 6.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.7ms preprocess, 5.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 1.7ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.8ms\n",
            "Speed: 1.6ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.8ms\n",
            "Speed: 1.4ms preprocess, 5.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.5ms\n",
            "Speed: 1.7ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 2.0ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.8ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.9ms preprocess, 5.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 1.9ms preprocess, 6.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 1.6ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.4ms\n",
            "Speed: 2.1ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.8ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.8ms\n",
            "Speed: 1.6ms preprocess, 5.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.4ms\n",
            "Speed: 1.4ms preprocess, 6.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.8ms\n",
            "Speed: 1.5ms preprocess, 5.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed 300 frames...\n",
            "\n",
            "0: 384x640 2 persons, 6.0ms\n",
            "Speed: 1.8ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.0ms\n",
            "Speed: 1.8ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 1.8ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 5.8ms\n",
            "Speed: 1.5ms preprocess, 5.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 5.9ms\n",
            "Speed: 1.6ms preprocess, 5.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.8ms preprocess, 6.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 1.8ms preprocess, 6.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.5ms\n",
            "Speed: 1.8ms preprocess, 7.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.5ms\n",
            "Speed: 1.9ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.0ms\n",
            "Speed: 2.4ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.8ms preprocess, 6.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.7ms\n",
            "Speed: 2.0ms preprocess, 6.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.7ms\n",
            "Speed: 1.9ms preprocess, 6.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.8ms\n",
            "Speed: 1.7ms preprocess, 6.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.5ms\n",
            "Speed: 1.8ms preprocess, 6.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.8ms\n",
            "Speed: 1.8ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.3ms\n",
            "Speed: 1.9ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 1.5ms preprocess, 6.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.3ms\n",
            "Speed: 2.1ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.8ms preprocess, 6.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.0ms\n",
            "Speed: 1.8ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.5ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 2.1ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.7ms\n",
            "Speed: 1.8ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.4ms\n",
            "Speed: 2.0ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 6.4ms\n",
            "Speed: 2.0ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.0ms\n",
            "Speed: 1.7ms preprocess, 6.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.2ms\n",
            "Speed: 1.9ms preprocess, 7.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.6ms\n",
            "Speed: 1.9ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.8ms\n",
            "Speed: 1.9ms preprocess, 6.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Video processing and data collection complete. Now analyzing tracking data.\n",
            "\n",
            "--- Tracking Analysis Results ---\n",
            "Total number of unique track IDs: 25\n",
            "Average track length (number of frames an ID appeared): 19.20 frames\n",
            "Quantitative assessment of identity switches and fragmentation often requires more complex metrics or qualitative review, which will be addressed in a later step.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code block is analyzing the tracking_df to provide key statistical insights into the confidence of detections for each unique tracked person."
      ],
      "metadata": {
        "id": "KpdaaAK0wyk1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31716f67",
        "outputId": "f215de64-e0ad-4d2c-ce1d-ea8431b2590a"
      },
      "source": [
        "confidence_stats = tracking_df.groupby('track_id')['confidence'].agg(['mean', 'min', 'max'])\n",
        "confidence_stats.rename(columns={'mean': 'average_confidence', 'min': 'min_confidence', 'max': 'max_confidence'}, inplace=True)\n",
        "\n",
        "print(\"Confidence statistics per track ID:\")\n",
        "print(confidence_stats)\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confidence statistics per track ID:\n",
            "          average_confidence  min_confidence  max_confidence\n",
            "track_id                                                    \n",
            "1                   0.048561             0.0        0.534171\n",
            "13                  0.139809             0.0        0.712133\n",
            "16                  0.186841             0.0        0.685995\n",
            "26                  0.067060             0.0        0.737658\n",
            "27                  0.073350             0.0        0.806849\n",
            "3                   0.301813             0.0        0.808013\n",
            "30                  0.063003             0.0        0.693038\n",
            "31                  0.057495             0.0        0.632446\n",
            "32                  0.124314             0.0        0.687419\n",
            "33                  0.113321             0.0        0.556122\n",
            "41                  0.058015             0.0        0.581155\n",
            "42                  0.137874             0.0        0.664552\n",
            "43                  0.046079             0.0        0.506872\n",
            "45                  0.124069             0.0        0.725245\n",
            "47                  0.360595             0.0        0.822684\n",
            "49                  0.070551             0.0        0.780373\n",
            "50                  0.364374             0.0        0.824422\n",
            "51                  0.105841             0.0        0.645947\n",
            "54                  0.061991             0.0        0.681899\n",
            "65                  0.075451             0.0        0.628438\n",
            "66                  0.117089             0.0        0.747291\n",
            "70                  0.110738             0.0        0.714603\n",
            "71                  0.210725             0.0        0.850190\n",
            "77                  0.185937             0.0        0.604807\n",
            "9                   0.131515             0.0        0.650061\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "492d0e24"
      },
      "source": [
        "### Summary of Confidence Score Analysis\n",
        "\n",
        "The confidence statistics (average, minimum, and maximum confidence) for each unique track ID have been calculated and displayed in a DataFrame. These metrics offer valuable insights into the reliability of the object detection during the tracking process for each individual:\n",
        "\n",
        "*   **Average Confidence (`average_confidence`)**: This indicates the general reliability of detections for a given track over its lifetime. Higher average confidence suggests more consistent and strong detections, implying a more stable track.\n",
        "*   **Minimum Confidence (`min_confidence`)**: A low minimum confidence (often 0.0, as seen in many tracks here) suggests frames where the object might have been partially occluded, blurry, or very far from the camera, leading to a weak or missed detection. Persistent low minimum confidence could indicate challenging tracking conditions for that specific object.\n",
        "*   **Maximum Confidence (`max_confidence`)**: High maximum confidence values (close to 1.0) indicate instances where the object was clearly detected and identified. This validates that the YOLOv8 model was able to confidently detect the object at some point during its track.\n",
        "\n",
        "**Implications for Tracking Reliability**:\n",
        "\n",
        "*   **Identity Switches and Fragmentation**: Tracks with consistently low average confidence or frequent occurrences of 0.0 minimum confidence might be prone to identity switches or track fragmentation. If a detection confidence drops too low, DeepSORT might lose the track and re-initialize a new one, leading to multiple IDs for the same person.\n",
        "*   **Robustness of Detection**: Tracks with high average confidence generally correspond to individuals who were consistently well-detected throughout their presence in the video, indicating good visibility and clear features for the YOLOv8 model to identify.\n",
        "*   **Thresholding**: Analyzing these statistics can help in refining the confidence threshold (`conf=0.5` in `model.predict`) for future tracking tasks. If many important tracks have average confidences below this threshold, it might indicate that a lower threshold could capture more detections, though potentially at the cost of more false positives.\n",
        "\n",
        "These confidence metrics serve as a quantitative assessment of how well YOLOv8 is detecting objects throughout their tracked paths, which directly impacts the overall quality and reliability of the DeepSORT tracking output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d95b024a",
        "outputId": "08788e70-dee2-4083-efab-0fd27054e569"
      },
      "source": [
        "print(\"Data for Track ID 77:\")\n",
        "print(tracking_df[tracking_df['track_id'] == '77'])\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data for Track ID 77:\n",
            "     frame_count track_id   bbox_xmin   bbox_ymin   bbox_xmax   bbox_ymax  \\\n",
            "468          329       77  508.046737  280.179945  549.047670  385.328807   \n",
            "469          330       77  507.888476  278.604820  548.913434  383.952460   \n",
            "470          331       77  508.054466  277.298730  549.395465  383.655049   \n",
            "471          332       77  508.121496  276.398404  549.306543  382.396215   \n",
            "472          333       77  508.093493  275.298530  549.420649  381.662084   \n",
            "473          334       77  508.065491  274.198656  549.534755  380.927954   \n",
            "474          335       77  508.037489  273.098782  549.648861  380.193824   \n",
            "475          336       77  508.009486  271.998908  549.762966  379.459694   \n",
            "476          337       77  507.981484  270.899034  549.877072  378.725563   \n",
            "477          338       77  507.953482  269.799160  549.991178  377.991433   \n",
            "478          339       77  507.925479  268.699286  550.105284  377.257303   \n",
            "479          340       77  507.897477  267.599412  550.219390  376.523173   \n",
            "\n",
            "     confidence  \n",
            "468    0.604807  \n",
            "469    0.581784  \n",
            "470    0.533088  \n",
            "471    0.511569  \n",
            "472    0.000000  \n",
            "473    0.000000  \n",
            "474    0.000000  \n",
            "475    0.000000  \n",
            "476    0.000000  \n",
            "477    0.000000  \n",
            "478    0.000000  \n",
            "479    0.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8e5873c8",
        "outputId": "a425a164-63a4-4623-8453-2aa43e071675"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set the aesthetic style of the plots\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Create a figure and a set of subplots\n",
        "plt.figure(figsize=(14, 7))\n",
        "\n",
        "# Plotting Average Confidence\n",
        "sns.barplot(x=confidence_stats.index, y=confidence_stats['average_confidence'], palette='viridis', hue=confidence_stats.index, legend=False)\n",
        "plt.xlabel('Track ID')\n",
        "plt.ylabel('Average Confidence')\n",
        "plt.title('Average Confidence Score per Track ID')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Plotting Max Confidence\n",
        "plt.figure(figsize=(14, 7))\n",
        "sns.barplot(x=confidence_stats.index, y=confidence_stats['max_confidence'], palette='magma', hue=confidence_stats.index, legend=False)\n",
        "plt.xlabel('Track ID')\n",
        "plt.ylabel('Maximum Confidence')\n",
        "plt.title('Maximum Confidence Score per Track ID')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Confidence statistics visualized successfully.\")\n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confidence statistics visualized successfully.\n"
          ]
        }
      ]
    }
  ]
}